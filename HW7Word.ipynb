{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co-YbUR87aPk",
        "outputId": "abcc5bf0-067d-4de7-a154-9dbfa45ff0a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy==1.10.0 in /usr/local/lib/python3.10/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scipy==1.10.0 numpy==1.23.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/stephenhky/PyShortTextCategorization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7stJqjn98FHS",
        "outputId": "37cea3a1-4fb9-4532-8e68-4d99068fa72e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/stephenhky/PyShortTextCategorization\n",
            "  Cloning https://github.com/stephenhky/PyShortTextCategorization to /tmp/pip-req-build-8lpfvxd2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/stephenhky/PyShortTextCategorization /tmp/pip-req-build-8lpfvxd2\n",
            "  Resolved https://github.com/stephenhky/PyShortTextCategorization to commit e183bac2a362051087e3cb9160ccd8f2ee67f315\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Cython>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (1.10.0)\n",
            "Requirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (1.2.2)\n",
            "Requirement already satisfied: tensorflow>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (2.15.0)\n",
            "Requirement already satisfied: keras>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (2.15.0)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (4.3.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (1.5.3)\n",
            "Requirement already satisfied: snowballstemmer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (2.2.0)\n",
            "Requirement already satisfied: transformers>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (4.38.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (2.1.0+cu121)\n",
            "Collecting python-Levenshtein>=0.21.0 (from shorttext==1.6.1)\n",
            "  Downloading python_Levenshtein-0.25.0-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from shorttext==1.6.1) (0.58.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.0.0->shorttext==1.6.1) (6.4.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->shorttext==1.6.1) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->shorttext==1.6.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->shorttext==1.6.1) (2023.4)\n",
            "Collecting Levenshtein==0.25.0 (from python-Levenshtein>=0.21.0->shorttext==1.6.1)\n",
            "  Downloading Levenshtein-0.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.1.0 (from Levenshtein==0.25.0->python-Levenshtein>=0.21.0->shorttext==1.6.1)\n",
            "  Downloading rapidfuzz-3.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->shorttext==1.6.1) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.13.0->shorttext==1.6.1) (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->shorttext==1.6.1) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->shorttext==1.6.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->shorttext==1.6.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->shorttext==1.6.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->shorttext==1.6.1) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->shorttext==1.6.1) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->shorttext==1.6.1) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->shorttext==1.6.1) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->shorttext==1.6.1) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->shorttext==1.6.1) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->shorttext==1.6.1) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->shorttext==1.6.1) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->shorttext==1.6.1) (4.66.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.13.0->shorttext==1.6.1) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.32.0->shorttext==1.6.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.32.0->shorttext==1.6.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.32.0->shorttext==1.6.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.32.0->shorttext==1.6.1) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->shorttext==1.6.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->shorttext==1.6.1) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->shorttext==1.6.1) (3.2.2)\n",
            "Building wheels for collected packages: shorttext\n",
            "  Building wheel for shorttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shorttext: filename=shorttext-1.6.1-cp310-cp310-linux_x86_64.whl size=724842 sha256=7da5b27f9c861d3ef8da1d8b9dfe01723eb21446217a0461ee0fabf44fd52bb6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r347qzv3/wheels/84/07/3e/bb56d79459e5c3c9111c649d174481179ef9258e9559bdd72c\n",
            "Successfully built shorttext\n",
            "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein, shorttext\n",
            "Successfully installed Levenshtein-0.25.0 python-Levenshtein-0.25.0 rapidfuzz-3.6.2 shorttext-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QCygsJ78L33",
        "outputId": "ea0fb7c8-df96-4c06-8108-a8d7be51f554"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpV-Ryed9auc",
        "outputId": "9abebb37-fcd5-490a-d273-5c6d8e98d896"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/ColabData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk1PewORGj1y",
        "outputId": "591e5db1-4271-4b01-d24a-31b659baec54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ColabData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import PlaintextCorpusReader\n",
        "corpus_root = 'MovieReviews' # Folder Name\n",
        "filelists = PlaintextCorpusReader(corpus_root, '.*',encoding='latin-1')  # wildcard is read all files in the folder\n",
        "filelists.fileids()  # Get the filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yzjyYgW9d1x",
        "outputId": "d81c18fb-1509-4186-eff0-deb8d1806b55"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['16748.txt',\n",
              " '17108.txt',\n",
              " '17109.txt',\n",
              " '17110.txt',\n",
              " '17111.txt',\n",
              " '17116.txt',\n",
              " '17117.txt',\n",
              " '17118.txt',\n",
              " '17119.txt',\n",
              " '17139.txt',\n",
              " '17144.txt',\n",
              " '17145.txt',\n",
              " '17146.txt',\n",
              " '17147.txt',\n",
              " '17150.txt',\n",
              " '17185.txt',\n",
              " '17192.txt',\n",
              " '17219.txt',\n",
              " '17239.txt',\n",
              " '17243.txt',\n",
              " '17254.txt',\n",
              " '17255.txt',\n",
              " '17280.txt',\n",
              " '17300.txt',\n",
              " '17303.txt',\n",
              " '17341.txt',\n",
              " '17384.txt',\n",
              " '17391.txt',\n",
              " '17398.txt',\n",
              " '17399.txt',\n",
              " '17430.txt',\n",
              " '17431.txt',\n",
              " '17447.txt',\n",
              " '17457.txt',\n",
              " '17460.txt',\n",
              " '17501.txt',\n",
              " '17518.txt',\n",
              " '17532.txt',\n",
              " '17534.txt',\n",
              " '17578.txt',\n",
              " '17609.txt',\n",
              " '17610.txt',\n",
              " '17655.txt',\n",
              " '17662.txt',\n",
              " '17663.txt',\n",
              " '17695.txt',\n",
              " '17711.txt',\n",
              " '17713.txt',\n",
              " '17753.txt',\n",
              " '17757.txt',\n",
              " '17758.txt',\n",
              " '17761.txt',\n",
              " '17803.txt',\n",
              " '17811.txt',\n",
              " '17874.txt',\n",
              " '17879.txt',\n",
              " '17886.txt',\n",
              " '17896.txt',\n",
              " '17898.txt',\n",
              " '17902.txt',\n",
              " '17912.txt',\n",
              " '17933.txt',\n",
              " '17934.txt',\n",
              " '17945.txt',\n",
              " '17963.txt',\n",
              " '17971.txt',\n",
              " '17992.txt',\n",
              " '18004.txt',\n",
              " '18016.txt',\n",
              " '18032.txt',\n",
              " '18067.txt',\n",
              " '18068.txt',\n",
              " '18080.txt',\n",
              " '18087.txt',\n",
              " '18088.txt',\n",
              " '18136.txt',\n",
              " '18141.txt',\n",
              " '18156.txt',\n",
              " '18161.txt',\n",
              " '18181.txt',\n",
              " '18227.txt',\n",
              " '18263.txt',\n",
              " '18272.txt',\n",
              " '18273.txt',\n",
              " '18274.txt',\n",
              " '18282.txt',\n",
              " '18283.txt',\n",
              " '18307.txt',\n",
              " '18368.txt',\n",
              " '18375.txt',\n",
              " '18376.txt',\n",
              " '18396.txt',\n",
              " '18406.txt',\n",
              " '18413.txt',\n",
              " '18414.txt',\n",
              " '18447.txt',\n",
              " '18473.txt',\n",
              " '18480.txt',\n",
              " '18485.txt',\n",
              " '18498.txt',\n",
              " '1858.txt',\n",
              " '1859.txt',\n",
              " '1860.txt',\n",
              " '1864.txt',\n",
              " '1865.txt',\n",
              " '1866.txt',\n",
              " '1867.txt',\n",
              " '1889.txt',\n",
              " '1891.txt',\n",
              " '1908.txt',\n",
              " '1910.txt',\n",
              " '1911.txt',\n",
              " '1912.txt',\n",
              " '1916.txt',\n",
              " '1917.txt',\n",
              " '1921.txt',\n",
              " '1925.txt',\n",
              " '1928.txt',\n",
              " '1929.txt',\n",
              " '1930.txt',\n",
              " '1932.txt',\n",
              " '1934.txt',\n",
              " '1937.txt',\n",
              " '1943.txt',\n",
              " '1944.txt',\n",
              " '1945.txt',\n",
              " '1961.txt',\n",
              " '1967.txt',\n",
              " '1968.txt',\n",
              " '1974.txt',\n",
              " '1975.txt',\n",
              " '1976.txt',\n",
              " '1979.txt',\n",
              " '1981.txt',\n",
              " '1984.txt',\n",
              " '1985.txt',\n",
              " '1990.txt',\n",
              " '1991.txt',\n",
              " '1994.txt',\n",
              " '1998.txt',\n",
              " '2005.txt',\n",
              " '2006.txt',\n",
              " '2007.txt',\n",
              " '2008.txt',\n",
              " '2009.txt',\n",
              " '2025.txt',\n",
              " '2026.txt',\n",
              " '2030.txt',\n",
              " '2031.txt',\n",
              " '2033.txt',\n",
              " '2035.txt',\n",
              " '2036.txt',\n",
              " '2043.txt',\n",
              " '2045.txt',\n",
              " '2046.txt',\n",
              " '2051.txt',\n",
              " '2055.txt',\n",
              " '2058.txt',\n",
              " '2059.txt',\n",
              " '2062.txt',\n",
              " '2067.txt',\n",
              " '2076.txt',\n",
              " '2079.txt',\n",
              " '2080.txt',\n",
              " '2081.txt',\n",
              " '2085.txt',\n",
              " '2086.txt',\n",
              " '2087.txt',\n",
              " '2089.txt',\n",
              " '2090.txt',\n",
              " '2091.txt',\n",
              " '2094.txt',\n",
              " '2095.txt',\n",
              " '2098.txt',\n",
              " '2099.txt',\n",
              " '2101.txt',\n",
              " '2108.txt',\n",
              " '2110.txt',\n",
              " '2113.txt',\n",
              " '2115.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie = []\n",
        "for fileid in filelists.fileids():\n",
        "    movie.append(filelists.raw(fileid))"
      ],
      "metadata": {
        "id": "Eaptihj59iTa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shorttext.utils import standard_text_preprocessor_1, DocumentTermMatrix\n",
        "preprocessor = standard_text_preprocessor_1()\n",
        "corpus = [preprocessor(article).split(' ') for article in movie]"
      ],
      "metadata": {
        "id": "BPQXnEKRk-iz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtm = DocumentTermMatrix(corpus, docids = filelists.fileids())"
      ],
      "metadata": {
        "id": "_x6B7h-mHyKq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtm.get_token_occurences('director')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRIkcaNVH0Fs",
        "outputId": "490b597f-f055-4fde-9ba9-528518eb2cd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'16748.txt': 3.0,\n",
              " '17108.txt': 3.0,\n",
              " '17109.txt': 1.0,\n",
              " '17110.txt': 2.0,\n",
              " '17111.txt': 1.0,\n",
              " '17116.txt': 1.0,\n",
              " '17117.txt': 5.0,\n",
              " '17118.txt': 1.0,\n",
              " '17119.txt': 5.0,\n",
              " '17139.txt': 1.0,\n",
              " '17144.txt': 1.0,\n",
              " '17145.txt': 2.0,\n",
              " '17146.txt': 2.0,\n",
              " '17147.txt': 1.0,\n",
              " '17150.txt': 1.0,\n",
              " '17185.txt': 3.0,\n",
              " '17192.txt': 4.0,\n",
              " '17219.txt': 1.0,\n",
              " '17239.txt': 2.0,\n",
              " '17243.txt': 1.0,\n",
              " '17254.txt': 1.0,\n",
              " '17255.txt': 1.0,\n",
              " '17280.txt': 2.0,\n",
              " '17300.txt': 2.0,\n",
              " '17303.txt': 2.0,\n",
              " '17341.txt': 1.0,\n",
              " '17384.txt': 2.0,\n",
              " '17398.txt': 1.0,\n",
              " '17399.txt': 3.0,\n",
              " '17430.txt': 2.0,\n",
              " '17431.txt': 2.0,\n",
              " '17447.txt': 1.0,\n",
              " '17457.txt': 1.0,\n",
              " '17460.txt': 2.0,\n",
              " '17501.txt': 1.0,\n",
              " '17518.txt': 1.0,\n",
              " '17534.txt': 1.0,\n",
              " '17578.txt': 1.0,\n",
              " '17609.txt': 1.0,\n",
              " '17610.txt': 1.0,\n",
              " '17655.txt': 1.0,\n",
              " '17663.txt': 1.0,\n",
              " '17695.txt': 2.0,\n",
              " '17711.txt': 1.0,\n",
              " '17713.txt': 2.0,\n",
              " '17753.txt': 1.0,\n",
              " '17757.txt': 2.0,\n",
              " '17758.txt': 2.0,\n",
              " '17761.txt': 1.0,\n",
              " '17803.txt': 1.0,\n",
              " '17811.txt': 1.0,\n",
              " '17874.txt': 2.0,\n",
              " '17879.txt': 1.0,\n",
              " '17886.txt': 3.0,\n",
              " '17896.txt': 1.0,\n",
              " '17898.txt': 1.0,\n",
              " '17902.txt': 1.0,\n",
              " '17912.txt': 2.0,\n",
              " '17933.txt': 2.0,\n",
              " '17934.txt': 1.0,\n",
              " '17945.txt': 2.0,\n",
              " '17963.txt': 2.0,\n",
              " '17971.txt': 3.0,\n",
              " '17992.txt': 1.0,\n",
              " '18004.txt': 1.0,\n",
              " '18016.txt': 1.0,\n",
              " '18032.txt': 1.0,\n",
              " '18067.txt': 1.0,\n",
              " '18068.txt': 3.0,\n",
              " '18080.txt': 3.0,\n",
              " '18087.txt': 3.0,\n",
              " '18088.txt': 2.0,\n",
              " '18136.txt': 1.0,\n",
              " '18141.txt': 1.0,\n",
              " '18156.txt': 2.0,\n",
              " '18161.txt': 1.0,\n",
              " '18181.txt': 4.0,\n",
              " '18227.txt': 1.0,\n",
              " '18263.txt': 2.0,\n",
              " '18272.txt': 4.0,\n",
              " '18273.txt': 2.0,\n",
              " '18274.txt': 1.0,\n",
              " '18282.txt': 1.0,\n",
              " '18283.txt': 1.0,\n",
              " '18307.txt': 8.0,\n",
              " '18368.txt': 3.0,\n",
              " '18376.txt': 2.0,\n",
              " '18396.txt': 1.0,\n",
              " '18406.txt': 2.0,\n",
              " '18413.txt': 2.0,\n",
              " '18414.txt': 1.0,\n",
              " '18447.txt': 3.0,\n",
              " '18473.txt': 1.0,\n",
              " '18480.txt': 1.0,\n",
              " '18485.txt': 1.0,\n",
              " '18498.txt': 3.0,\n",
              " '1858.txt': 1.0,\n",
              " '1859.txt': 1.0,\n",
              " '1860.txt': 4.0,\n",
              " '1864.txt': 1.0,\n",
              " '1865.txt': 1.0,\n",
              " '1866.txt': 1.0,\n",
              " '1867.txt': 1.0,\n",
              " '1889.txt': 1.0,\n",
              " '1891.txt': 1.0,\n",
              " '1908.txt': 1.0,\n",
              " '1910.txt': 1.0,\n",
              " '1911.txt': 1.0,\n",
              " '1912.txt': 1.0,\n",
              " '1917.txt': 3.0,\n",
              " '1921.txt': 1.0,\n",
              " '1925.txt': 1.0,\n",
              " '1928.txt': 1.0,\n",
              " '1929.txt': 1.0,\n",
              " '1930.txt': 1.0,\n",
              " '1932.txt': 1.0,\n",
              " '1944.txt': 2.0,\n",
              " '1945.txt': 2.0,\n",
              " '1961.txt': 2.0,\n",
              " '1967.txt': 1.0,\n",
              " '1968.txt': 1.0,\n",
              " '1974.txt': 1.0,\n",
              " '1975.txt': 2.0,\n",
              " '1976.txt': 3.0,\n",
              " '1981.txt': 2.0,\n",
              " '1984.txt': 1.0,\n",
              " '1985.txt': 1.0,\n",
              " '1990.txt': 3.0,\n",
              " '1994.txt': 1.0,\n",
              " '2005.txt': 1.0,\n",
              " '2006.txt': 1.0,\n",
              " '2007.txt': 1.0,\n",
              " '2008.txt': 1.0,\n",
              " '2009.txt': 1.0,\n",
              " '2025.txt': 2.0,\n",
              " '2026.txt': 1.0,\n",
              " '2030.txt': 2.0,\n",
              " '2031.txt': 1.0,\n",
              " '2036.txt': 2.0,\n",
              " '2045.txt': 1.0,\n",
              " '2046.txt': 1.0,\n",
              " '2051.txt': 1.0,\n",
              " '2055.txt': 1.0,\n",
              " '2058.txt': 1.0,\n",
              " '2059.txt': 1.0,\n",
              " '2062.txt': 2.0,\n",
              " '2076.txt': 3.0,\n",
              " '2080.txt': 1.0,\n",
              " '2081.txt': 1.0,\n",
              " '2085.txt': 1.0,\n",
              " '2086.txt': 1.0,\n",
              " '2087.txt': 2.0,\n",
              " '2089.txt': 1.0,\n",
              " '2090.txt': 1.0,\n",
              " '2091.txt': 1.0,\n",
              " '2094.txt': 1.0,\n",
              " '2095.txt': 1.0,\n",
              " '2098.txt': 1.0,\n",
              " '2099.txt': 3.0,\n",
              " '2110.txt': 1.0,\n",
              " '2113.txt': 1.0,\n",
              " '2115.txt': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def entropy(p):\n",
        "    if sum(p) == 0:\n",
        "        return 0\n",
        "\n",
        "    p = p/sum(p)\n",
        "\n",
        "    p = p[ p > 0 ]\n",
        "\n",
        "    H = -sum(p*np.log2(p))\n",
        "\n",
        "    return H"
      ],
      "metadata": {
        "id": "qTQKFwV6IlS1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "direct_count = list(dtm.get_token_occurences('director').values())\n",
        "direct_docs = list(dtm.get_token_occurences('director').keys())"
      ],
      "metadata": {
        "id": "QsSKusqeI4hx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(entropy(direct_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cB53VXUJurl",
        "outputId": "820a7adc-860b-4057-9933-6742b854c46e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.122166395775948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ber = filelists.fileids()[:80]\n",
        "sch = filelists.fileids()[-100:]\n",
        "print(len(ber))\n",
        "print(len(sch))"
      ],
      "metadata": {
        "id": "69xUH2hKL6B8",
        "outputId": "7dce617f-51e7-4c36-855f-244eb2d6a50c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtm.get_token_occurences('director').keys()"
      ],
      "metadata": {
        "id": "PKNtAoyXP2AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "associ_docs = list(dtm.get_token_occurences('director').keys())\n",
        "associ_docs"
      ],
      "metadata": {
        "id": "cyJizT-LPvBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ber_count = sum([1 for doc in direct_docs if doc in ber])\n",
        "sch_count = sum([1 for doc in direct_docs if doc in sch])\n",
        "print(ber_count)\n",
        "print(sch_count)"
      ],
      "metadata": {
        "id": "cuwLeNGdPctY",
        "outputId": "ea67c95d-6d0f-4d0a-e45e-d616c5097983",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77\n",
            "85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.reshape((ber_count,80-ber_count\n",
        "                    ,sch_count,100-sch_count),(2,2))\n",
        "array"
      ],
      "metadata": {
        "id": "LaX0QQYVlZ6G",
        "outputId": "4ad4ede2-a8f1-4ebd-93e8-8c10b2306be0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[77,  3],\n",
              "       [85, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(array, axis = 0)"
      ],
      "metadata": {
        "id": "00QgqddqlzzK",
        "outputId": "ee04b02e-bc94-4f9e-b8ba-325b9e9e2320",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([162,  18])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entropy(np.array( [162,18]))"
      ],
      "metadata": {
        "id": "row_V9G2l2ng",
        "outputId": "0c819769-e41e-44aa-debf-47ab98f3220f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4689955935892812"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(array, axis = 1)"
      ],
      "metadata": {
        "id": "0syKx4Mll-xU",
        "outputId": "0d455515-4cc4-409f-d040-018de8330baf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 80, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entropy_class = entropy(np.sum(array, axis = 1))\n",
        "entropy_class"
      ],
      "metadata": {
        "id": "PpfevGsUmCE9",
        "outputId": "d14d9bfa-9604-4e85-c553-d5fd58479c9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9910760598382222"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_probs = np.sum(array, axis = 0)/180\n",
        "column_probs"
      ],
      "metadata": {
        "id": "AWgnQtskmHgM",
        "outputId": "7468f392-381b-4c02-8f42-958d28736ade",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9, 0.1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_entropy = np.apply_along_axis(entropy, 0, array)\n",
        "column_entropy"
      ],
      "metadata": {
        "id": "Y-pwCwNOmNsr",
        "outputId": "ce092d2b-9309-4b98-bf5a-64fcd760126c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99824017, 0.65002242])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_probs*column_entropy"
      ],
      "metadata": {
        "id": "H6BbGZnSmTvm",
        "outputId": "5a992857-f675-4f27-9103-99c9cd985a79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.89841615, 0.06500224])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conditional_entropy = sum(column_probs*column_entropy)\n",
        "conditional_entropy"
      ],
      "metadata": {
        "id": "TyjeQNJumXmV",
        "outputId": "36eed321-4bd2-46ba-bb7e-6c7eaf3f0a65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9634183936209307"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MI_direct = entropy_class - conditional_entropy\n",
        "MI_direct"
      ],
      "metadata": {
        "id": "BWO-1vWvmeUy",
        "outputId": "9e6254ab-d579-412c-b3e7-37954daddfa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.027657666217291488"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = {}\n",
        "for doc in corpus:\n",
        "  for word in doc:\n",
        "    if word not in words:\n",
        "      words[word] = 1\n",
        "    else:\n",
        "      words[word] += 1"
      ],
      "metadata": {
        "id": "fIJ7nFx8r845"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_ten(word):\n",
        "    direct_count = list(dtm.get_token_occurences(word).values())\n",
        "    direct_docs = list(dtm.get_token_occurences(word).keys())\n",
        "\n",
        "    entropy_value = entropy(direct_count)\n",
        "\n",
        "    ber_count = sum([1 for doc in direct_docs if doc in ber])\n",
        "    sch_count = sum([1 for doc in direct_docs if doc in sch])\n",
        "\n",
        "    array = np.reshape((ber_count,80-ber_count\n",
        "                    ,sch_count,100-sch_count),(2,2))\n",
        "\n",
        "    marginal_entropy = entropy(np.sum(array, axis=1))\n",
        "\n",
        "    column_prob = np.sum(array, axis=0)/180\n",
        "\n",
        "    column_entropy = np.apply_along_axis(entropy, 0, array)\n",
        "\n",
        "    conditional_entropy = sum(column_prob * column_entropy)\n",
        "\n",
        "    mi = marginal_entropy - conditional_entropy\n",
        "    return mi\n",
        "\n",
        "scores = {}\n",
        "for word in words.keys():\n",
        "  score = top_ten(word)\n",
        "  scores[word] = score\n",
        "\n",
        "sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "for word, scores in sorted_words[:10]:\n",
        "    print(f\"{word}: {scores}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pZVruLpQnHdf",
        "outputId": "15c3d789-c980-49b7-cee5-0ce4330a2aee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reserv: 0.5360547127375266\n",
            "denni: 0.5177766824991015\n",
            "schwartz\n",
            ": 0.49202296056300543\n",
            "right: 0.34124798879941887\n",
            "there: 0.29684962309392304\n",
            "howev: 0.27421790253727896\n",
            "releas: 0.2702108404097968\n",
            "cast: 0.2564686677667559\n",
            "screenplai: 0.2564686677667559\n",
            "produc: 0.23020448708340835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A word having a high mutual information with the author means that that word can be a strong predictor to the author as well as writing style."
      ],
      "metadata": {
        "id": "YB0Vur2Huaws"
      }
    }
  ]
}